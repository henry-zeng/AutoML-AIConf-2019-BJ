{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/remote-amlcompute/auto-ml-remote-amlcompute.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Automated Machine Learning\n_**Remote Execution using AmlCompute**_\n\n## Contents\n1. [Introduction](#Introduction)\n1. [Setup](#Setup)\n1. [Data](#Data)\n1. [Train](#Train)\n1. [Results](#Results)\n1. [Test](#Test)\n\n**This notebook showcase how to run aumoml on remote compute. There are 3 quiz in this notebook, finish the quiz to win T-shirt!**"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Introduction\nIn this example we use the scikit-learn's [digit dataset](http://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwritten-digits-dataset) to showcase how you can use AutoML for a simple classification problem.\n\nMake sure you have executed the [configuration](../../../configuration.ipynb) before running this notebook.\n\nIn this notebook you would see\n1. Create an `Experiment` in an existing `Workspace`.\n2. Create or Attach existing AmlCompute to a workspace.\n3. Configure AutoML using `AutoMLConfig`.\n4. Train the model using AmlCompute\n5. Explore the results.\n6. Test the best fitted model.\n\nIn addition this notebook showcases the following features\n- **Parallel** executions for iterations\n- **Asynchronous** tracking of progress\n- **Cancellation** of individual iterations or the entire run\n- Retrieving models for any iteration or logged metric\n- Specifying AutoML settings as `**kwargs`"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Setup\n\nAs part of the setup you have already created an Azure ML `Workspace` object. For AutoML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import logging\nimport os\nimport csv\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\n\nimport azureml.core\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.train.automl import AutoMLConfig",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()\n\n# Choose a name for the run history container in the workspace.\nexperiment_name = 'automl-remote-amlcompute'\nproject_folder = './project'\n\nexperiment = Experiment(ws, experiment_name)\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace Name'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Project Directory'] = project_folder\noutput['Experiment Name'] = experiment.name\npd.set_option('display.max_colwidth', -1)\noutputDf = pd.DataFrame(data = output, index = [''])\noutputDf.T",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SDK version</th>\n      <td>1.0.43</td>\n    </tr>\n    <tr>\n      <th>Subscription ID</th>\n      <td>ea8323fb-dd33-48d1-8ffb-3d771bc5f05c</td>\n    </tr>\n    <tr>\n      <th>Workspace Name</th>\n      <td>gpu-tech-immersion-aml-70617</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>ODL-aml-workspace-70617</td>\n    </tr>\n    <tr>\n      <th>Location</th>\n      <td>southeastasia</td>\n    </tr>\n    <tr>\n      <th>Project Directory</th>\n      <td>./project</td>\n    </tr>\n    <tr>\n      <th>Experiment Name</th>\n      <td>automl-remote-amlcompute</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                       \nSDK version        1.0.43                              \nSubscription ID    ea8323fb-dd33-48d1-8ffb-3d771bc5f05c\nWorkspace Name     gpu-tech-immersion-aml-70617        \nResource Group     ODL-aml-workspace-70617             \nLocation           southeastasia                       \nProject Directory  ./project                           \nExperiment Name    automl-remote-amlcompute            "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### ***Quiz 1 - whitelist models***\n*please fill in below cell to whitelist models, supported algotithms can be found here:https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.constants.supportedalgorithms?view=azure-ml-py *"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "whitelist_models=[\"XGBoostClassifier\",\"RandomForestClassifier\",\"LightGBMClassifier\"]\n",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create or Attach existing AmlCompute\nYou will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for your AutoML run. In this tutorial, you create an AmlCompute as your training compute resource.\n\nAs with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import AmlCompute\nfrom azureml.core.compute import ComputeTarget\n\n# Choose a name for your cluster.\namlcompute_cluster_name = \"cpucluster\"\n\nfound = False\n\n# Check if this compute target already exists in the workspace.\n\ncts = ws.compute_targets\nif amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n    found = True\n    print('Found existing compute target.')\n    compute_target = cts[amlcompute_cluster_name]\n\nif not found:\n    print('Creating a new compute target...')\n    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", # for GPU, use \"STANDARD_NC6\"\n                                                                #vm_priority = 'lowpriority', # optional\n                                                                max_nodes = 6)\n\n    # Create the cluster.\\n\",\n    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n\n    # Can poll for a minimum number of nodes and for a specific timeout.\n    # If no min_node_count is provided, it will use the scale settings for the cluster.\n    compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n\n     # For a more detailed view of current AmlCompute status, use get_status().",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found existing compute target.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data\nFor remote executions, you need to make the data accessible from the remote compute.\nThis can be done by uploading the data to DataStore.\nIn this example, we upload scikit-learn's [load_digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_train = datasets.load_digits()\n\nif not os.path.isdir('data'):\n    os.mkdir('data')\n    \nif not os.path.exists(project_folder):\n    os.makedirs(project_folder)\n    \npd.DataFrame(data_train.data).to_csv(\"data/X_train.tsv\", index=False, header=False, quoting=csv.QUOTE_ALL, sep=\"\\t\")\npd.DataFrame(data_train.target).to_csv(\"data/y_train.tsv\", index=False, header=False, sep=\"\\t\")\n\nds = ws.get_default_datastore()\nds.upload(src_dir='./data', target_path='bai_data', overwrite=True, show_progress=True)\n\nfrom azureml.core.runconfig import DataReferenceConfiguration\ndr = DataReferenceConfiguration(datastore_name=ds.name, \n                   path_on_datastore='bai_data', \n                   path_on_compute='/tmp/azureml_runs',\n                   mode='download', # download files from datastore to compute target\n                   overwrite=False)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Uploading ./data/X_train.tsv\nUploading ./data/nyc_energy.csv\nUploading ./data/y_train.tsv\nUploaded ./data/y_train.tsv, 1 files out of an estimated total of 3\nUploaded ./data/X_train.tsv, 2 files out of an estimated total of 3\nUploaded ./data/nyc_energy.csv, 3 files out of an estimated total of 3\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\n\n# create a new RunConfig object\nconda_run_config = RunConfiguration(framework=\"python\")\n\n# Set compute target to AmlCompute\nconda_run_config.target = compute_target\nconda_run_config.environment.docker.enabled = True\nconda_run_config.environment.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE\n\n# set the data reference of the run coonfiguration\nconda_run_config.data_references = {ds.name: dr}\n\ncd = CondaDependencies.create(pip_packages=['azureml-sdk[automl]'], conda_packages=['numpy','py-xgboost<=0.80'])\nconda_run_config.environment.python.conda_dependencies = cd",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile $project_folder/get_data.py\n\nimport pandas as pd\n\ndef get_data():\n    X_train = pd.read_csv(\"/tmp/azureml_runs/bai_data/X_train.tsv\", delimiter=\"\\t\", header=None, quotechar='\"')\n    y_train = pd.read_csv(\"/tmp/azureml_runs/bai_data/y_train.tsv\", delimiter=\"\\t\", header=None, quotechar='\"')\n\n    return { \"X\" : X_train.values, \"y\" : y_train[0].values }\n",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting ./project/get_data.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train\n\nYou can specify `automl_settings` as `**kwargs` as well. Also note that you can use a `get_data()` function for local excutions too.\n\n**Note:** When using AmlCompute, you can't pass Numpy arrays directly to the fit method.\n\n|Property|Description|\n|-|-|\n|**primary_metric**|This is the metric that you want to optimize. Classification supports the following primary metrics: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n|**iterations**|Number of iterations. In each iteration AutoML trains a specific pipeline with the data.|\n|**n_cross_validations**|Number of cross validation splits.|\n|**max_concurrent_iterations**|Maximum number of iterations that would be executed in parallel. This should be less than the number of cores on the DSVM.|"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### *** Quiz 2 - fill automl_settings***\n*Fill below cell to set automl_settings with below requirement*\n\n|Property|Description|\n|-|-|\n|**primary_metric**|AUC_weighted|\n|**iteration_timeout_minutes**|10|\n|**iterations**|10|\n|**n_cross_validations**|5|\n|**max_concurrent_iterations**|2|"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_settings = {\n    \"iteration_timeout_minutes\": 10,\n    \"iterations\": 10,\n    \"n_cross_validations\": 5,\n    \"primary_metric\": 'AUC_weighted',\n    \"preprocess\": False,\n    \"max_concurrent_iterations\": 2,\n    \"verbosity\": logging.INFO\n}\n\nautoml_config = AutoMLConfig(task = 'classification',\n                             debug_log = 'automl_errors.log',\n                             path = project_folder,\n                             run_configuration=conda_run_config,\n                             data_script = project_folder + \"/get_data.py\",\n                             **automl_settings\n                            )\n",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Call the `submit` method on the experiment object and pass the run configuration. For remote runs the execution is asynchronous, so you will see the iterations get populated as they complete. You can interact with the widgets and models even when the experiment is running to retrieve the best model up to that point. Once you are satisfied with the model, you can cancel a particular iteration or the whole run.\nIn this example, we specify `show_output = False` to suppress console output while the run is in progress."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "remote_run = experiment.submit(automl_config, show_output = False)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "remote_run",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-remote-amlcompute</td><td>AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a</td><td>automl</td><td>Preparing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/ea8323fb-dd33-48d1-8ffb-3d771bc5f05c/resourceGroups/ODL-aml-workspace-70617/providers/Microsoft.MachineLearningServices/workspaces/gpu-tech-immersion-aml-70617/experiments/automl-remote-amlcompute/runs/AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: automl-remote-amlcompute,\nId: AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a,\nType: automl,\nStatus: Preparing)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Results\n\n#### Loading executed runs\nIn case you need to load a previously executed run, enable the cell below and replace the `run_id` value."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": " remote_run = AutoMLRun(experiment = experiment, run_id = 'AutoML_4fa1e293-ac8f-4181-a1c4-05e118ff6ad9\t')"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Widget for Monitoring Runs\n\nThe widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n\nYou can click on a pipeline to see run properties and output logs.  Logs are also available on the DSVM under `/tmp/azureml_run/{iterationid}/azureml-logs`\n\n**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "remote_run",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-remote-amlcompute</td><td>AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a</td><td>automl</td><td>Preparing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/ea8323fb-dd33-48d1-8ffb-3d771bc5f05c/resourceGroups/ODL-aml-workspace-70617/providers/Microsoft.MachineLearningServices/workspaces/gpu-tech-immersion-aml-70617/experiments/automl-remote-amlcompute/runs/AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: automl-remote-amlcompute,\nId: AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a,\nType: automl,\nStatus: Preparing)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(remote_run).show() ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cf6e2107372466d9bb60b9a1677d65e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sâ€¦"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Wait until the run finishes.\nremote_run.wait_for_completion(show_output = True)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n****************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n****************************************************************************************************\n\n ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n         1   StandardScalerWrapper SGD                      0:00:38       0.9972    0.9972\n         0   StandardScalerWrapper SGD                      0:01:30       0.9943    0.9972\n         2   MinMaxScaler LightGBM                          0:00:43       0.9979    0.9979\n         3   StandardScalerWrapper SGD                      0:00:46       0.9888    0.9979\n         4   StandardScalerWrapper ExtremeRandomTrees       0:00:42       0.9965    0.9979\n         6   StandardScalerWrapper SGD                      0:00:40       0.9966    0.9979\n         5   StandardScalerWrapper LightGBM                 0:00:44       0.9979    0.9979\n         7   MinMaxScaler RandomForest                      0:00:45       0.9851    0.9979\n         8    VotingEnsemble                                0:00:46       0.9987    0.9987\n         9    StackEnsemble                                 0:01:00       0.9988    0.9988\n\nExecution Summary\n=================\nRunId: AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a\n\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "{'runId': 'AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a',\n 'target': 'cpucluster',\n 'status': 'Completed',\n 'startTimeUtc': '2019-06-18T01:27:09.933429Z',\n 'endTimeUtc': '2019-06-18T01:32:29.300158Z',\n 'properties': {'num_iterations': '10',\n  'training_type': 'TrainFull',\n  'acquisition_function': 'EI',\n  'primary_metric': 'AUC_weighted',\n  'train_split': '0',\n  'MaxTimeSeconds': '600',\n  'acquisition_parameter': '0',\n  'num_cross_validation': '5',\n  'target': 'cpucluster',\n  'RawAMLSettingsString': \"{'name': 'automl-remote-amlcompute', 'path': './project', 'subscription_id': 'ea8323fb-dd33-48d1-8ffb-3d771bc5f05c', 'resource_group': 'ODL-aml-workspace-70617', 'workspace_name': 'gpu-tech-immersion-aml-70617', 'region': 'southeastasia', 'compute_target': 'cpucluster', 'spark_service': None, 'iterations': 10, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': './project/get_data.py', 'validation_size': 0.0, 'n_cross_validations': 5, 'y_min': None, 'y_max': None, 'num_classes': None, 'preprocess': False, 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': 1, 'max_concurrent_iterations': 2, 'iteration_timeout_minutes': 10, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': None, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['XGBoostClassifier', 'XGBoostClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': False, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'model_explainability': False, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': False, 'enable_feature_sweeping': True, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_early_stopping': False, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': True, 'ensemble_iterations': 10, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'cost_mode': 0, 'metric_operation': 'maximize'}\",\n  'AMLSettingsJsonString': '{\\n  \"name\": \"automl-remote-amlcompute\",\\n  \"path\": \"./project\",\\n  \"subscription_id\": \"ea8323fb-dd33-48d1-8ffb-3d771bc5f05c\",\\n  \"resource_group\": \"ODL-aml-workspace-70617\",\\n  \"workspace_name\": \"gpu-tech-immersion-aml-70617\",\\n  \"region\": \"southeastasia\",\\n  \"compute_target\": \"cpucluster\",\\n  \"spark_service\": null,\\n  \"iterations\": 10,\\n  \"primary_metric\": \"AUC_weighted\",\\n  \"task_type\": \"classification\",\\n  \"data_script\": \"./project/get_data.py\",\\n  \"validation_size\": 0.0,\\n  \"n_cross_validations\": 5,\\n  \"y_min\": null,\\n  \"y_max\": null,\\n  \"num_classes\": null,\\n  \"preprocess\": false,\\n  \"lag_length\": 0,\\n  \"is_timeseries\": false,\\n  \"max_cores_per_iteration\": 1,\\n  \"max_concurrent_iterations\": 2,\\n  \"iteration_timeout_minutes\": 10,\\n  \"mem_in_mb\": null,\\n  \"enforce_time_on_windows\": false,\\n  \"experiment_timeout_minutes\": null,\\n  \"experiment_exit_score\": null,\\n  \"whitelist_models\": null,\\n  \"blacklist_algos\": [\\n    \"XGBoostClassifier\",\\n    \"XGBoostClassifier\"\\n  ],\\n  \"auto_blacklist\": true,\\n  \"blacklist_samples_reached\": false,\\n  \"exclude_nan_labels\": true,\\n  \"verbosity\": 20,\\n  \"debug_log\": \"automl_errors.log\",\\n  \"show_warnings\": false,\\n  \"model_explainability\": false,\\n  \"service_url\": null,\\n  \"sdk_url\": null,\\n  \"sdk_packages\": null,\\n  \"enable_onnx_compatible_models\": false,\\n  \"enable_feature_sweeping\": true,\\n  \"telemetry_verbosity\": \"INFO\",\\n  \"send_telemetry\": true,\\n  \"enable_early_stopping\": false,\\n  \"early_stopping_n_iters\": 10,\\n  \"metrics\": null,\\n  \"enable_ensembling\": true,\\n  \"enable_stack_ensembling\": true,\\n  \"ensemble_iterations\": 10,\\n  \"enable_tf\": false,\\n  \"enable_cache\": true,\\n  \"enable_subsampling\": false,\\n  \"subsample_seed\": null,\\n  \"cost_mode\": 0,\\n  \"metric_operation\": \"maximize\"\\n}',\n  'DataPrepJsonString': None,\n  'EnableSubsampling': 'False',\n  'runTemplate': 'AutoML',\n  'azureml.runsource': 'automl',\n  'display_task_type': 'classification',\n  'dependencies_versions': '{\"azureml-widgets\": \"1.0.33\", \"azureml-train\": \"1.0.43\", \"azureml-train-restclients-hyperdrive\": \"1.0.43\", \"azureml-train-core\": \"1.0.43\", \"azureml-train-automl\": \"1.0.43.1\", \"azureml-telemetry\": \"1.0.43.1\", \"azureml-sdk\": \"1.0.43\", \"azureml-pipeline\": \"1.0.43\", \"azureml-pipeline-steps\": \"1.0.43\", \"azureml-pipeline-core\": \"1.0.43\", \"azureml-explain-model\": \"1.0.43\", \"azureml-dataprep\": \"1.1.5\", \"azureml-dataprep-native\": \"13.0.0\", \"azureml-core\": \"1.0.43\", \"azureml-contrib-opendatasets\": \"1.0.33\", \"azureml-contrib-notebook\": \"1.0.33\", \"azureml-automl-core\": \"1.0.43\"}',\n  'ContentSnapshotId': '6db047b3-4caf-4a5c-acaa-709a326efb67',\n  'snapshotId': '6db047b3-4caf-4a5c-acaa-709a326efb67',\n  'SetupRunId': 'AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a_setup',\n  'azureml.git.repository_uri': 'https://github.com/henry-zeng/AutoML-AIConf-2019-BJ',\n  'mlflow.source.git.repoURL': 'https://github.com/henry-zeng/AutoML-AIConf-2019-BJ',\n  'azureml.git.branch': 'master',\n  'mlflow.source.git.branch': 'master',\n  'azureml.git.commit': '756acee893ebc5c8e7cc31e8268939be84588a80',\n  'mlflow.source.git.commit': '756acee893ebc5c8e7cc31e8268939be84588a80',\n  'azureml.git.dirty': 'True',\n  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"dataset_classes\": 10, \"dataset_features\": 64, \"dataset_samples\": 1797, \"is_sparse\": false, \"subsampling\": false}'},\n 'logFiles': {}}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\n#### Retrieve All Child Runs\nYou can also use SDK methods to fetch all the child runs and see individual metrics that we log."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "children = list(remote_run.get_children())\nmetricslist = {}\nfor run in children:\n    properties = run.get_properties()\n    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n    metricslist[int(properties['iteration'])] = metrics\n\nrundata = pd.DataFrame(metricslist).sort_index(1)\nrundata",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AUC_macro</th>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>AUC_micro</th>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>AUC_weighted</th>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>average_precision_score_macro</th>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.94</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.98</td>\n      <td>0.92</td>\n      <td>0.99</td>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th>average_precision_score_micro</th>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.93</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.92</td>\n      <td>0.99</td>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th>average_precision_score_weighted</th>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.94</td>\n      <td>0.98</td>\n      <td>0.99</td>\n      <td>0.98</td>\n      <td>0.92</td>\n      <td>0.99</td>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th>balanced_accuracy</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>f1_score_macro</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>f1_score_micro</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>f1_score_weighted</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>log_loss</th>\n      <td>0.55</td>\n      <td>0.23</td>\n      <td>0.31</td>\n      <td>1.63</td>\n      <td>0.77</td>\n      <td>0.32</td>\n      <td>0.30</td>\n      <td>1.04</td>\n      <td>0.31</td>\n      <td>0.13</td>\n    </tr>\n    <tr>\n      <th>norm_macro_recall</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.90</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.95</td>\n      <td>0.85</td>\n      <td>0.96</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>precision_score_macro</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>precision_score_micro</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>precision_score_weighted</th>\n      <td>0.96</td>\n      <td>0.96</td>\n      <td>0.95</td>\n      <td>0.91</td>\n      <td>0.95</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.87</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>recall_score_macro</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>recall_score_micro</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>recall_score_weighted</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>weighted_accuracy</th>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>0.94</td>\n      <td>0.91</td>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                    0    1    2    3    4    5    6    7    8  \\\nAUC_macro                        0.99 1.00 1.00 0.99 1.00 1.00 1.00 0.99 1.00   \nAUC_micro                        0.99 1.00 1.00 0.99 1.00 1.00 1.00 0.99 1.00   \nAUC_weighted                     0.99 1.00 1.00 0.99 1.00 1.00 1.00 0.99 1.00   \naccuracy                         0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \naverage_precision_score_macro    0.98 0.99 0.99 0.94 0.98 0.99 0.98 0.92 0.99   \naverage_precision_score_micro    0.98 0.99 0.99 0.93 0.98 0.99 0.99 0.92 0.99   \naverage_precision_score_weighted 0.98 0.99 0.99 0.94 0.98 0.99 0.98 0.92 0.99   \nbalanced_accuracy                0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \nf1_score_macro                   0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \nf1_score_micro                   0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \nf1_score_weighted                0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \nlog_loss                         0.55 0.23 0.31 1.63 0.77 0.32 0.30 1.04 0.31   \nnorm_macro_recall                0.95 0.96 0.94 0.90 0.94 0.94 0.95 0.85 0.96   \nprecision_score_macro            0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \nprecision_score_micro            0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \nprecision_score_weighted         0.96 0.96 0.95 0.91 0.95 0.94 0.96 0.87 0.97   \nrecall_score_macro               0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \nrecall_score_micro               0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \nrecall_score_weighted            0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \nweighted_accuracy                0.95 0.96 0.94 0.91 0.94 0.94 0.96 0.86 0.97   \n\n                                    9  \nAUC_macro                        1.00  \nAUC_micro                        1.00  \nAUC_weighted                     1.00  \naccuracy                         0.97  \naverage_precision_score_macro    0.99  \naverage_precision_score_micro    0.99  \naverage_precision_score_weighted 0.99  \nbalanced_accuracy                0.97  \nf1_score_macro                   0.97  \nf1_score_micro                   0.97  \nf1_score_weighted                0.97  \nlog_loss                         0.13  \nnorm_macro_recall                0.97  \nprecision_score_macro            0.97  \nprecision_score_micro            0.97  \nprecision_score_weighted         0.97  \nrecall_score_macro               0.97  \nrecall_score_micro               0.97  \nrecall_score_weighted            0.97  \nweighted_accuracy                0.97  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Cancelling Runs\n\nYou can cancel ongoing remote runs using the `cancel` and `cancel_iteration` functions."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Cancel the ongoing experiment and stop scheduling new iterations.\n# remote_run.cancel()\n\n# Cancel iteration 1 and move onto iteration 2.\n# remote_run.cancel_iteration(1)",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Retrieve the Best Model\n\nBelow we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing.  Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run, fitted_model = remote_run.get_output()\nprint(best_run)\nprint(fitted_model)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: automl-remote-amlcompute,\nId: AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a_9,\nType: azureml.scriptrun,\nStatus: Completed)\nPipeline(memory=None,\n     steps=[('stackensembleclassifier', StackEnsembleClassifier(base_learners=[('2', Pipeline(memory=None,\n     steps=[('MinMaxScaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('LightGBMClassifier', LightGBMClassifier(boosting_type='goss', class_weight=None,\n          colsample_bytree=0.792222222...7f4392756358>,\n           solver='lbfgs', tol=0.0001, verbose=0),\n            training_cv_folds=5))])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Best Model Based on Any Other Metric\nShow the run and the model which has the smallest `log_loss` value:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "lookup_metric = \"log_loss\"\nbest_run, fitted_model = remote_run.get_output(metric = lookup_metric)\nprint(best_run)\nprint(fitted_model)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: automl-remote-amlcompute,\nId: AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a_9,\nType: azureml.scriptrun,\nStatus: Completed)\nPipeline(memory=None,\n     steps=[('stackensembleclassifier', StackEnsembleClassifier(base_learners=[('2', Pipeline(memory=None,\n     steps=[('MinMaxScaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('LightGBMClassifier', LightGBMClassifier(boosting_type='goss', class_weight=None,\n          colsample_bytree=0.792222222...7f4392756320>,\n           solver='lbfgs', tol=0.0001, verbose=0),\n            training_cv_folds=5))])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### *Quiz 3 - Retrieve model from specific iteration*\n*Please fill in below cell to retrieve the model from 7th iteration*"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "iteration = 7\nseventh_run, seventh_model = remote_run.get_output(iteration = iteration)\nprint(seventh_run)\nprint(seventh_model)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: automl-remote-amlcompute,\nId: AutoML_5adc1476-4b77-46a8-857c-5dd8dd210b6a_7,\nType: azureml.scriptrun,\nStatus: Completed)\nPipeline(memory=None,\n     steps=[('MinMaxScaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('RandomForestClassifier', RandomForestClassifier(bootstrap=False, class_weight='balanced',\n            criterion='entropy', max_depth=None, max_features='sqrt',\n            max_leaf_nodes=None, min_impurity_decrease=0.0,\n      ...n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False))])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test\n\n#### Load Test Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "digits = datasets.load_digits()\nX_test = digits.data[:10, :]\ny_test = digits.target[:10]\nimages = digits.images[:10]",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Testing Our Best Fitted Model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Randomly select digits and test.\nfor index in np.random.choice(len(y_test), 2, replace = False):\n    print(index)\n    predicted = fitted_model.predict(X_test[index:index + 1])[0]\n    label = y_test[index]\n    title = \"Label value = %d  Predicted value = %d \" % (label, predicted)\n    fig = plt.figure(1, figsize=(3,3))\n    ax1 = fig.add_axes((0,0,.8,.8))\n    ax1.set_title(title)\n    plt.imshow(images[index], cmap = plt.cm.gray_r, interpolation = 'nearest')\n    plt.show()",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "5\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 216x216 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": "9\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 216x216 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "savitam"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
