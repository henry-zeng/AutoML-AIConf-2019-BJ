{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/classification-with-onnx/auto-ml-classification-with-onnx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz - MNIST ONNX Model Registration and Deployment\n",
    "_**Register best MNIST model trained by AutoML and deploy it for inferencing**_\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Results](#Results)\n",
    "1. [Test](#Test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this example we use the scikit-learn's [digit dataset](http://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwritten-digits-dataset) to showcase how you can use AutoML for a simple classification problem and register the best trained model then deploy it for inferencing.\n",
    "\n",
    "Make sure you have executed the [configuration](https://github.com/Azure/MachineLearningNotebooks/blob/master/configuration.ipynb) before running this notebook.\n",
    "\n",
    "Please find the ONNX related documentations [here](https://github.com/onnx/onnx).\n",
    "\n",
    "In this notebook you will learn how to:\n",
    "1. Create an `Experiment` in an existing `Workspace`.\n",
    "2. Configure AutoML using `AutoMLConfig`.\n",
    "3. Train the model using local compute with ONNX compatible config on.\n",
    "4. Explore the results and save the ONNX model.\n",
    "5. Register the saved ONNX model into AML. You can skip step 3 and step 4 if you have the model ready.\n",
    "6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As part of the setup you have already created an Azure ML `Workspace` object. For AutoML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Choose a name for the experiment and specify the project folder.\n",
    "experiment_name = 'automl-classification-onnx'\n",
    "project_folder = './sample_projects/automl-classification-onnx'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace Name'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare MNIST dataset\n",
    "In order to train on the MNIST dataset we will first need to download it from Yan LeCun's web site directly and save them in a `data` folder locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# Download if the dataset does not exist on local machine.\n",
    "#\n",
    "\n",
    "if not os.path.exists('./data/mnist'):\n",
    "    os.makedirs('./data/mnist', exist_ok=True)\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename = './data/mnist/train-images.gz')\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename = './data/mnist/train-labels.gz')\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename = './data/mnist/test-images.gz')\n",
    "    urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename = './data/mnist/test-labels.gz')\n",
    "else:\n",
    "    print(\"MNIST dataset exists on local machine. Skip downloading.\")\n",
    "\n",
    "#\n",
    "# Load the dataset.\n",
    "#\n",
    "\n",
    "from src.utils import load_data\n",
    "\n",
    "# Note we also shrink the intensity values (X) from 0-255 to 0-1.\n",
    "X_train = load_data('./data/mnist/train-images.gz', False) / 255.0\n",
    "y_train = load_data('./data/mnist/train-labels.gz', True).reshape(-1)\n",
    "\n",
    "X_test = load_data('./data/mnist/test-images.gz', False) / 255.0\n",
    "y_test = load_data('./data/mnist/test-labels.gz', True).reshape(-1)\n",
    "\n",
    "#\n",
    "# Show some sample images.\n",
    "#\n",
    "\n",
    "count = 0\n",
    "sample_size = 30\n",
    "plt.figure(figsize = (16, 6))\n",
    "for i in np.random.permutation(X_train.shape[0])[:sample_size]:\n",
    "    count = count + 1\n",
    "    plt.subplot(1, sample_size, count)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    plt.text(x = 10, y = -10, s = y_train[i], fontsize = 18)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap = plt.cm.Greys)\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "# Convert X_train and X_test to pandas DataFrame and set column names,\n",
    "# This is needed for initializing the input variable names of ONNX model, \n",
    "# and the prediction with the ONNX model using the inference helper.\n",
    "#\n",
    "\n",
    "columns = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    columns.append(\"C\" + str(i + 1).zfill(3))\n",
    "X_train_df = pd.DataFrame(X_train, columns=columns)\n",
    "X_test_df = pd.DataFrame(X_test, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with enable ONNX compatible models config on\n",
    "\n",
    "Instantiate an `AutoMLConfig` object to specify the settings and data used to run the experiment.\n",
    "\n",
    "Set the parameter enable_onnx_compatible_models=True, if you also want to generate the ONNX compatible models. Please note, the forecasting task and TensorFlow models are not ONNX compatible yet.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|classification or regression|\n",
    "|**primary_metric**|This is the metric that you want to optimize. Classification supports the following primary metrics: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n",
    "|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n",
    "|**iterations**|Number of iterations. In each iteration AutoML trains a specific pipeline with the data.|\n",
    "|**X**|(sparse) array-like, shape = [n_samples, n_features]|\n",
    "|**y**|(sparse) array-like, shape = [n_samples, ], Multi-class targets.|\n",
    "|**enable_onnx_compatible_models**|Enable the ONNX compatible models in the experiment.|\n",
    "|**path**|Relative path to the project folder. AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = os.path.join(project_folder, 'automl_errors.log'),\n",
    "                             primary_metric = 'AUC_weighted',\n",
    "                             iteration_timeout_minutes = 60,\n",
    "                             iterations = 5,\n",
    "                             verbosity = logging.INFO,\n",
    "                             X = X_train_df,\n",
    "                             y = y_train,\n",
    "                             preprocess=True,\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             path = project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `submit` method on the experiment object and pass the run configuration. Execution of local runs is synchronous. Depending on the data and the number of iterations this can run for a while.\n",
    "In this example, we specify `show_output = True` to print currently running iterations to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Widget for Monitoring Runs\n",
    "\n",
    "The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
    "\n",
    "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(local_run).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the best ONNX model\n",
    "\n",
    "Below we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing.  Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*.\n",
    "\n",
    "Set the parameter return_onnx_model=True to retrieve the best ONNX model, instead of the Python model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, onnx_mdl = local_run.get_output(return_onnx_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.automl.core.onnx_convert import OnnxConverter\n",
    "onnx_fl_path = os.path.join(project_folder, \"best_model.onnx\")\n",
    "OnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register your model with Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = project_folder # replace this with the location of your model files\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(workspace = ws,\n",
    "                       model_path = model_dir + \"/\" + \"best_model.onnx\",\n",
    "                       model_name = \"mnist_best_onnx\",\n",
    "                       tags = {\"onnx\": \"demo\"},\n",
    "                       description = \"MNIST image classification from AutoML\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the registered model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime\n",
    "from azureml.core.model import Model\n",
    "\n",
    "#session = onnxruntime.InferenceSession(model_dir + \"/best_model.onnx\", None)\n",
    "session = onnxruntime.InferenceSession(Model.get_model_path(model_name = 'mnist_best_onnx'), None)\n",
    "\n",
    "print(Model.get_model_path(model_name = 'mnist_best_onnx'))\n",
    "\n",
    "k = 66\n",
    "X_test_k = X_test[k].tolist()\n",
    "y_test_k = y_test[k]\n",
    "\n",
    "print(\"Ground truth:\", y_test_k)\n",
    "\n",
    "session_input = {}\n",
    "for x in session.get_inputs():\n",
    "    i = int(x.name[1:]) - 1 # x.name should be 'CXXX', in which 'XXX' indicates the column index starting from 1.\n",
    "    session_input[x.name] = np.array([X_test_k[i]]).astype('float32')\n",
    "\n",
    "r = session.run([session.get_outputs()[0].name], session_input)\n",
    "\n",
    "print(\"Prediction:  \", r[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify our score and environment files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to deploy our ONNX Model on AML with inference in ONNX Runtime. We begin by writing a score.py file, which will help us run the model in our Azure ML virtual machine (VM), and then specify our environment by writing a yml file. You will also notice that we import the onnxruntime library to do runtime inference on our ONNX models (passing in input and evaluating out model's predicted output). More information on the API and commands can be found in the [ONNX Runtime documentation](https://aka.ms/onnxruntime).\n",
    "\n",
    "### Write score file\n",
    "\n",
    "A score file is what tells our Azure cloud service what to do. After initializing our model using azureml.core.model, we start an ONNX Runtime inference session to evaluate the data passed in on our function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import sys\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "import time\n",
    "\n",
    "\n",
    "def init():\n",
    "    global session, input_name, output_name\n",
    "    model = Model.get_model_path(model_name = 'mnist_best_onnx')\n",
    "    session = onnxruntime.InferenceSession(model, None)\n",
    "\n",
    "\n",
    "def run(input_data):\n",
    "\n",
    "    try:\n",
    "        # load in our data, convert to readable format\n",
    "        data = np.array(json.loads(input_data)['data']).astype('float32').tolist()\n",
    "        session_input = {}\n",
    "        for x in session.get_inputs():\n",
    "            i = int(x.name[1:]) - 1 # x.name should be 'CXXX', in which 'XXX' indicates the column index starting from 1.\n",
    "            session_input[x.name] = np.array([data[i]]).astype('float32')\n",
    "\n",
    "        # start timer\n",
    "        start = time.time()\n",
    "\n",
    "        r = session.run([session.get_outputs()[0].name], session_input)\n",
    "\n",
    "        #end timer\n",
    "        end = time.time()\n",
    "\n",
    "        result_dict = {\"result\": int(r[0][0]),\n",
    "                      \"time_in_sec\": end - start}\n",
    "    except Exception as e:\n",
    "        result_dict = {\"error\": str(e)}\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write environment file\n",
    "\n",
    "This step creates a YAML environment file that specifies which dependencies we would like to see in our Linux Virtual Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=[\"numpy\", \"onnxruntime\", \"azureml-core\"])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "RUN apt-get update\n",
    "RUN apt-get install -y libgomp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Container Image\n",
    "This step will likely take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  docker_file = \"Dockerfile\",\n",
    "                                                  description = \"MNIST ONNX Runtime container\",\n",
    "                                                  tags = {\"demo\": \"onnx\"}) \n",
    "\n",
    "\n",
    "image = ContainerImage.create(name = \"onnximage\",\n",
    "                              # this is the model object\n",
    "                              models = [model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you need to debug your code, the next line of code accesses the log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're all done specifying what we want our virtual machine to do. Let's configure and deploy our container image.\n",
    "\n",
    "### Deploy the container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {'demo': 'onnx'}, \n",
    "                                               description = 'ONNX for mnist model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will likely take a few minutes to run as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = 'onnx-demo-mnist'\n",
    "print(\"Service\", aci_service_name)\n",
    "\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aci_service.state != 'Healthy':\n",
    "    # run this command for debugging.\n",
    "    print(aci_service.get_logs())\n",
    "\n",
    "# If your deployment fails, make sure to delete your aci_service or rename your service before trying again!\n",
    "# aci_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success!\n",
    "\n",
    "If you've made it this far, you've deployed a working VM with a handwritten digit classifier running in the cloud using Azure ML. Congratulations!\n",
    "\n",
    "You can get the URL for the webservice with the code below. Let's now see how well our model deals with our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aci_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some sample images in X_test\n",
    "We use `matplotlib` to plot 10 test images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 6))\n",
    "for k in np.arange(10):\n",
    "    plt.subplot(1, 15, k+1)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    plt.imshow(X_test[k].reshape(28, 28), cmap = plt.cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation / prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 6), frameon=False)\n",
    "plt.subplot(1, 11, 1)\n",
    "\n",
    "plt.text(x = 0, y = -30, s = \"True Label: \", fontsize = 11, color = 'black')\n",
    "plt.text(x = 0, y = -20, s = \"Result: \", fontsize = 11, color = 'black')\n",
    "plt.text(x = 0, y = -10, s = \"Inference Time: \", fontsize = 11, color = 'black')\n",
    "plt.text(x = 3, y = 14, s = \"Model Input\", fontsize = 10, color = 'black')\n",
    "plt.text(x = 6, y = 18, s = \"(28 x 28)\", fontsize = 10, color = 'black')\n",
    "plt.imshow(np.ones((28,28)), cmap=plt.cm.Greys)    \n",
    "\n",
    "\n",
    "for i in np.arange(10):\n",
    "    \n",
    "    input_data = json.dumps({'data': X_test[i].tolist()})\n",
    "    \n",
    "    \n",
    "    # predict using the deployed model\n",
    "    r = aci_service.run(input_data)\n",
    "    \n",
    "    if \"error\" in r:\n",
    "        print(\"Error:\", r['error'])\n",
    "        break\n",
    "        \n",
    "    result = r['result']\n",
    "    time_ms = np.round(r['time_in_sec'] * 1000, 2)\n",
    "    \n",
    "    ground_truth = int(y_test[i])\n",
    "    \n",
    "    # compare actual value vs. the predicted values:\n",
    "    plt.subplot(1, 11, i+2)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "\n",
    "    # use different color for misclassified sample\n",
    "    font_color = 'red' if ground_truth != result else 'black'\n",
    "    clr_map = plt.cm.gray if ground_truth != result else plt.cm.Greys\n",
    "\n",
    "    # ground truth labels are in blue\n",
    "    plt.text(x = 10, y = -30, s = ground_truth, fontsize = 18, color = 'blue')\n",
    "    \n",
    "    # predictions are in black if correct, red if incorrect\n",
    "    plt.text(x = 10, y = -20, s = result, fontsize = 18, color = font_color)\n",
    "    plt.text(x = 5, y = -10, s = str(time_ms) + ' ms', fontsize = 14, color = font_color)\n",
    "\n",
    "    \n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap = clr_map)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try classifying your own images!\n",
    "\n",
    "Create your own handwritten image and pass it into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions take your image and format it so it can be passed\n",
    "# as input into our ONNX model\n",
    "\n",
    "import cv2\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"Convert the input image into grayscale\"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "def resize_img(img_to_resize):\n",
    "    \"\"\"Resize image to MNIST model input dimensions\"\"\"\n",
    "    r_img = cv2.resize(img_to_resize, dsize=(28, 28), interpolation=cv2.INTER_AREA)\n",
    "    r_img.resize((1, 1, 28, 28))\n",
    "    return r_img\n",
    "\n",
    "def preprocess(img_to_preprocess):\n",
    "    \"\"\"Resize input images and convert them to grayscale.\"\"\"\n",
    "    if img_to_preprocess.shape == (28, 28):\n",
    "        img_to_preprocess.resize((1, 1, 28, 28))\n",
    "        return img_to_preprocess\n",
    "    \n",
    "    grayscale = rgb2gray(img_to_preprocess)\n",
    "    processed_img = resize_img(grayscale)\n",
    "    return processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this string with your own path/test image\n",
    "# Make sure your image is square and the dimensions are equal (i.e. 100 * 100 pixels or 28 * 28 pixels)\n",
    "\n",
    "# Any PNG or JPG image file should work\n",
    "\n",
    "your_test_image = \"<path to file>\"\n",
    "\n",
    "# e.g. your_test_image = \"C:/Users/vinitra.swamy/Pictures/handwritten_digit.png\"\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "if your_test_image != \"<path to file>\":\n",
    "    img = mpimg.imread(your_test_image)\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(img, cmap = plt.cm.Greys)\n",
    "    print(\"Old Dimensions: \", img.shape)\n",
    "    img = preprocess(img)\n",
    "    print(\"New Dimensions: \", img.shape)\n",
    "else:\n",
    "    img = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if img is None:\n",
    "    print(\"Add the path for your image data.\")\n",
    "else:\n",
    "    input_data = json.dumps({'data': img.tolist()})\n",
    "\n",
    "    try:\n",
    "        r = aci_service.run(input_data)\n",
    "        result = r['result']\n",
    "        time_ms = np.round(r['time_in_sec'] * 1000, 2)\n",
    "    except KeyError as e:\n",
    "        print(str(e))\n",
    "\n",
    "    plt.figure(figsize = (16, 6))\n",
    "    plt.subplot(1, 15,1)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    plt.text(x = -100, y = -20, s = \"Model prediction: \", fontsize = 14)\n",
    "    plt.text(x = -100, y = -10, s = \"Inference time: \", fontsize = 14)\n",
    "    plt.text(x = 0, y = -20, s = str(result), fontsize = 14)\n",
    "    plt.text(x = 0, y = -10, s = str(time_ms) + \" ms\", fontsize = 14)\n",
    "    plt.text(x = -100, y = 14, s = \"Input image: \", fontsize = 14)\n",
    "    plt.imshow(img.reshape(28, 28), cmap = plt.cm.gray)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to delete your service after you are done using it!\n",
    "\n",
    "aci_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations!\n",
    "\n",
    "In this tutorial, you have:\n",
    "- familiarized yourself with ONNX Runtime inference and the pretrained models in the ONNX model zoo\n",
    "- understood a state-of-the-art convolutional neural net image classification model (MNIST in ONNX) and deployed it in Azure ML cloud\n",
    "- ensured that your deep learning model is working perfectly (in the cloud) on test data, and checked it against some of your own!\n",
    "\n",
    "Next steps:\n",
    "- Check out another interesting application based on a Microsoft Research computer vision paper that lets you set up a [facial emotion recognition model](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/deployment/onnx/onnx-inference-facial-expression-recognition-deploy.ipynb) in the cloud! This tutorial deploys a pre-trained ONNX Computer Vision model in an Azure ML virtual machine.\n",
    "- Contribute to our [open source ONNX repository on github](http://github.com/onnx/onnx) and/or add to our [ONNX model zoo](http://github.com/onnx/models)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "savitam"
   }
  ],
  "kernelspec": {
   "display_name": "Python (azure_automl)",
   "language": "python",
   "name": "azure_automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
