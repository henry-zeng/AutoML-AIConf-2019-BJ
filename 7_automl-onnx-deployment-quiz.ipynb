{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/classification-with-onnx/auto-ml-classification-with-onnx.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Quiz - MNIST ONNX Model Registration and Deployment\n_**Register best MNIST model trained by AutoML and deploy it for inferencing**_\n\n## Introduction\nIn this notebook, you need to register the MNIST model you trained with AutoML in [notebook 5](https://github.com/henry-zeng/AutoML-AIConf-2019-BJ/blob/master/5_automl-classification-with-onnx.ipynb) and using what you learned in [notebook 6](https://github.com/henry-zeng/AutoML-AIConf-2019-BJ/blob/master/6_onnx-inference-mnist-deploy.ipynb) to deploy in ACI for inferencing. Below lists the key steps you need to complete:\n\n1. Setup\n2. Register your model with Azure ML\n3. Specify score and environment files\n4. Write docker file and create container image\n5. Deploy\n\nAfter you complete these steps, you can use the sample code we provide to verify and test the deployed web service."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Setup\n\nAs part of the setup you have already created an Azure ML `Workspace` object. For AutoML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import logging\nimport os\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\n\nimport azureml.core\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()\n\n# Choose a name for the experiment and specify the project folder.\nexperiment_name = 'automl-classification-onnx'\nproject_folder = './projects/automl-classification-onnx'\n\nexperiment = Experiment(ws, experiment_name)\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace Name'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Project Directory'] = project_folder\noutput['Experiment Name'] = experiment.name\npd.set_option('display.max_colwidth', -1)\noutputDf = pd.DataFrame(data = output, index = [''])\noutputDf.T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Register your model with Azure ML"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Reference code in notebook 6: https://github.com/henry-zeng/AutoML-AIConf-2019-BJ/blob/master/6_onnx-inference-mnist-deploy.ipynb\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Verify the registered model is working"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You can use the following code to verify if your registered model is working\n'''\nimport numpy as np\nimport onnxruntime\nfrom azureml.core.model import Model\n\nsession = onnxruntime.InferenceSession(Model.get_model_path(model_name = 'mnist_best_onnx'), None)\n\nprint(Model.get_model_path(model_name = 'mnist_best_onnx'))\n\nk = 66\nX_test_k = X_test[k].tolist()\ny_test_k = y_test[k]\n\nprint(\"Ground truth:\", y_test_k)\n\nsession_input = {}\nfor x in session.get_inputs():\n    i = int(x.name[1:]) - 1 # x.name should be 'CXXX', in which 'XXX' indicates the column index starting from 1.\n    session_input[x.name] = np.array([X_test_k[i]]).astype('float32')\n\nr = session.run([session.get_outputs()[0].name], session_input)\n\nprint(\"Prediction:  \", r[0][0])\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Specify our score and environment files"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We are now going to deploy our ONNX Model on AML with inference in ONNX Runtime. We begin by writing a score.py file, which will help us run the model in our Azure ML virtual machine (VM), and then specify our environment by writing a yml file. You will also notice that we import the onnxruntime library to do runtime inference on our ONNX models (passing in input and evaluating out model's predicted output). More information on the API and commands can be found in the [ONNX Runtime documentation](https://aka.ms/onnxruntime).\n\n### Write score file\n\nA score file is what tells our Azure cloud service what to do. After initializing our model using azureml.core.model, we start an ONNX Runtime inference session to evaluate the data passed in on our function calls."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# The score file below is a reference for you.\n'''\n%%writefile score.py\nimport json\nimport numpy as np\nimport onnxruntime\nimport sys\nimport os\nfrom azureml.core.model import Model\nimport time\n\n\ndef init():\n    global session, input_name, output_name\n    model = Model.get_model_path(model_name = 'mnist_best_onnx')\n    session = onnxruntime.InferenceSession(model, None)\n\n\ndef run(input_data):\n\n    try:\n        # load in our data, convert to readable format\n        data = np.array(json.loads(input_data)['data']).astype('float32').tolist()\n        session_input = {}\n        for x in session.get_inputs():\n            i = int(x.name[1:]) - 1 # x.name should be 'CXXX', in which 'XXX' indicates the column index starting from 1.\n            session_input[x.name] = np.array([data[i]]).astype('float32')\n\n        # start timer\n        start = time.time()\n\n        r = session.run([session.get_outputs()[0].name], session_input)\n\n        #end timer\n        end = time.time()\n\n        result_dict = {\"result\": int(r[0][0]),\n                      \"time_in_sec\": end - start}\n    except Exception as e:\n        result_dict = {\"error\": str(e)}\n\n    return result_dict\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Write environment file\n\nThis step creates a YAML environment file that specifies which dependencies we would like to see in our Linux Virtual Machine."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Reference code in notebook 6: https://github.com/henry-zeng/AutoML-AIConf-2019-BJ/blob/master/6_onnx-inference-mnist-deploy.ipynb\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Write Dockerfile"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create the Container Image\nThis step will likely take a few minutes."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Reference code in notebook 6: https://github.com/henry-zeng/AutoML-AIConf-2019-BJ/blob/master/6_onnx-inference-mnist-deploy.ipynb\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We're all done specifying what we want our virtual machine to do. Let's configure and deploy our container image.\n\n### Deploy the container image"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Reference code in notebook 6: https://github.com/henry-zeng/AutoML-AIConf-2019-BJ/blob/master/6_onnx-inference-mnist-deploy.ipynb\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Success!\n\nIf you've made it this far, you've deployed a working VM with a handwritten digit classifier running in the cloud using Azure ML. Congratulations!\n\nYou can get the URL for the webservice with the code below. Let's now see how well our model deals with our test images."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# print(aci_service.scoring_uri)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Show some sample images in X_test\nWe use `matplotlib` to plot 10 test images from the dataset."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.figure(figsize = (16, 6))\nfor k in np.arange(10):\n    plt.subplot(1, 15, k+1)\n    plt.axhline('')\n    plt.axvline('')\n    plt.imshow(X_test[k].reshape(28, 28), cmap = plt.cm.Greys)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Run evaluation / prediction"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "plt.figure(figsize = (16, 6), frameon=False)\nplt.subplot(1, 11, 1)\n\nplt.text(x = 0, y = -30, s = \"True Label: \", fontsize = 11, color = 'black')\nplt.text(x = 0, y = -20, s = \"Result: \", fontsize = 11, color = 'black')\nplt.text(x = 0, y = -10, s = \"Inference Time: \", fontsize = 11, color = 'black')\nplt.text(x = 3, y = 14, s = \"Model Input\", fontsize = 10, color = 'black')\nplt.text(x = 6, y = 18, s = \"(28 x 28)\", fontsize = 10, color = 'black')\nplt.imshow(np.ones((28,28)), cmap=plt.cm.Greys)    \n\n\nfor i in np.arange(10):\n    \n    input_data = json.dumps({'data': X_test[i].tolist()})\n    \n    \n    # predict using the deployed model\n    r = aci_service.run(input_data)\n    \n    if \"error\" in r:\n        print(\"Error:\", r['error'])\n        break\n        \n    result = r['result']\n    time_ms = np.round(r['time_in_sec'] * 1000, 2)\n    \n    ground_truth = int(y_test[i])\n    \n    # compare actual value vs. the predicted values:\n    plt.subplot(1, 11, i+2)\n    plt.axhline('')\n    plt.axvline('')\n\n    # use different color for misclassified sample\n    font_color = 'red' if ground_truth != result else 'black'\n    clr_map = plt.cm.gray if ground_truth != result else plt.cm.Greys\n\n    # ground truth labels are in blue\n    plt.text(x = 10, y = -30, s = ground_truth, fontsize = 18, color = 'blue')\n    \n    # predictions are in black if correct, red if incorrect\n    plt.text(x = 10, y = -20, s = result, fontsize = 18, color = font_color)\n    plt.text(x = 5, y = -10, s = str(time_ms) + ' ms', fontsize = 14, color = font_color)\n\n    \n    plt.imshow(X_test[i].reshape(28, 28), cmap = clr_map)\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Try classifying your own images!\n\nCreate your own handwritten image and pass it into the model."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Preprocessing functions take your image and format it so it can be passed\n# as input into our ONNX model\n\nimport cv2\n\ndef rgb2gray(rgb):\n    \"\"\"Convert the input image into grayscale\"\"\"\n    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n\ndef resize_img(img_to_resize):\n    \"\"\"Resize image to MNIST model input dimensions\"\"\"\n    r_img = cv2.resize(img_to_resize, dsize=(28, 28), interpolation=cv2.INTER_AREA)\n    r_img.resize((1, 1, 28, 28))\n    return r_img\n\ndef preprocess(img_to_preprocess):\n    \"\"\"Resize input images and convert them to grayscale.\"\"\"\n    if img_to_preprocess.shape == (28, 28):\n        img_to_preprocess.resize((1, 1, 28, 28))\n        return img_to_preprocess\n    \n    grayscale = rgb2gray(img_to_preprocess)\n    processed_img = resize_img(grayscale)\n    return processed_img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Replace this string with your own path/test image\n# Make sure your image is square and the dimensions are equal (i.e. 100 * 100 pixels or 28 * 28 pixels)\n\n# Any PNG or JPG image file should work\n\nyour_test_image = \"<path to file>\"\n\n# e.g. your_test_image = \"C:/Users/vinitra.swamy/Pictures/handwritten_digit.png\"\n\nimport matplotlib.image as mpimg\n\nif your_test_image != \"<path to file>\":\n    img = mpimg.imread(your_test_image)\n    plt.subplot(1,3,1)\n    plt.imshow(img, cmap = plt.cm.Greys)\n    print(\"Old Dimensions: \", img.shape)\n    img = preprocess(img)\n    print(\"New Dimensions: \", img.shape)\nelse:\n    img = None",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "if img is None:\n    print(\"Add the path for your image data.\")\nelse:\n    input_data = json.dumps({'data': img.tolist()})\n\n    try:\n        r = aci_service.run(input_data)\n        result = r['result']\n        time_ms = np.round(r['time_in_sec'] * 1000, 2)\n    except KeyError as e:\n        print(str(e))\n\n    plt.figure(figsize = (16, 6))\n    plt.subplot(1, 15,1)\n    plt.axhline('')\n    plt.axvline('')\n    plt.text(x = -100, y = -20, s = \"Model prediction: \", fontsize = 14)\n    plt.text(x = -100, y = -10, s = \"Inference time: \", fontsize = 14)\n    plt.text(x = 0, y = -20, s = str(result), fontsize = 14)\n    plt.text(x = 0, y = -10, s = str(time_ms) + \" ms\", fontsize = 14)\n    plt.text(x = -100, y = 14, s = \"Input image: \", fontsize = 14)\n    plt.imshow(img.reshape(28, 28), cmap = plt.cm.gray)    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# remember to delete your service after you are done using it!\n\n# aci_service.delete()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "savitam"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}